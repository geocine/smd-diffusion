{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU7NuMAA2drw",
        "outputId": "3de37d2f-2ebb-42ca-918c-6123fbc9cf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4, 15109 MiB, 15109 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown Check type of GPU and VRAM available. Make sure we have atleast a T4 GPU.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "#@markdown Install dependencies. You don't need to change any of these settings. Make sure to run this before running any cells below.\n",
        "!wget -q -O train_dreambooth.py https://github.com/geocine/smd-diffusion/raw/main/train_dreambooth.py\n",
        "!wget -q -O convert_diffusers_to_original_stable_diffusion.py https://github.com/geocine/smd-diffusion/raw/main/convert_diffusers_to_original_stable_diffusion.py\n",
        "!wget -q -O concepts_list.json https://github.com/geocine/smd-diffusion/raw/main/concepts_list.json\n",
        "# URLs of the diffusers and xformers packages\n",
        "import subprocess\n",
        "DIFFUSERS_URL = 'git+https://github.com/ShivamShrirao/diffusers'\n",
        "XFORMERS_URL = 'https://github.com/geocine/dreamstall-binaries/releases/download/cxx-p38-txx-linux/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl'\n",
        "FORCE_REINSTALL = False #@param {type:\"boolean\"}\n",
        "\n",
        "def install_package(package, force_reinstall=False):\n",
        "    # Check if the package is already installed using pip freeze\n",
        "    installed_packages = subprocess.run([\"pip\", \"freeze\"], capture_output=True).stdout.decode().split(\"\\n\")\n",
        "    if not force_reinstall and any(package in s for s in installed_packages):\n",
        "        print(f'{package} is already installed')\n",
        "        return\n",
        "\n",
        "    if package == 'diffusers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"-qq\", \"install\", DIFFUSERS_URL], capture_output=True, text=True)\n",
        "    elif package == 'xformers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"-qq\", \"install\", XFORMERS_URL], capture_output=True, text=True)\n",
        "    else:\n",
        "        # Install the package using pip\n",
        "        result = subprocess.run([\"pip\", \"-q\", \"install\", package], capture_output=True, text=True)\n",
        "\n",
        "    # Print the output of the command\n",
        "    print(result.stdout)\n",
        "\n",
        "# List of packages to check and install\n",
        "packages = ['diffusers', 'triton', 'accelerate==0.12.0', 'transformers', 'ftfy', 'bitsandbytes', 'gradio', 'natsort', 'xformers']\n",
        "\n",
        "# Check and install each package\n",
        "for package in packages:\n",
        "    install_package(package, FORCE_REINSTALL)\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## Settings\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Details about <code>{SDD_TOKEN}</code> and <code>{SDD_CLASS}</code></summary>\n",
        "\n",
        "  - `SDD_TOKEN` - corresponds to the unique identifier which will reference the subject we want to add. This name should be unique, so we donâ€™t have to compete with an existing representation\n",
        "  - `SDD_CLASS` - use generic classes such as man, woman, or child (if the subject is a person) or cat or dog (if the subject is a pet)\n",
        "\n",
        "  > You could explore other classes. In this Colab I use the class `supermodel` by default since I get good results in training my personal subjects\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rxg0y5MBudmd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from huggingface_hub import hf_hub_download\n",
        "import subprocess\n",
        "\n",
        "SDD_TOKEN = \"zwx\" #@param {type:\"string\"}\n",
        "SDD_CLASS = \"supermodel\" #@param {type:\"string\"}\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    raise ValueError(\"Please run the Install cell first\")\n",
        "\n",
        "# Open the JSON file and read the contents\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "  json_data = json.load(f)\n",
        "\n",
        "# Iterate over the object and replace the placeholders with the values\n",
        "for item in json_data:\n",
        "  for key, value in item.items():\n",
        "    item[key] = value.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "\n",
        "# Open the JSON file and write the updated contents\n",
        "with open(\"/content/concepts_list.json\", \"w\") as f:\n",
        "  json.dump(json_data, f, indent=2)\n",
        "\n",
        "#@markdown You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an [access token](https://huggingface.co/settings/tokens) for the code to work.\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# check if HUGGINGFACE_TOKEN is set\n",
        "if not HUGGINGFACE_TOKEN:\n",
        "    raise ValueError(\"Please set HUGGINGFACE_TOKEN first\")\n",
        "\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = f\"stable_diffusion_models/{SDD_TOKEN}\"\n",
        "OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "  # Remove all files inside the directory\n",
        "  for file in os.listdir(OUTPUT_DIR):\n",
        "    os.remove(os.path.join(OUTPUT_DIR, file))\n",
        "else:\n",
        "  # Create the directory\n",
        "  os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(f\"[*] Models will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "unzip_directory = f\"/content/data/{SDD_CLASS}\"\n",
        "\n",
        "# Check if the unzip directory exists\n",
        "try:\n",
        "  # Get a list of the files in the unzip directory\n",
        "  files = os.listdir(unzip_directory)\n",
        "except FileNotFoundError:\n",
        "  # Create the unzip directory\n",
        "  os.makedirs(unzip_directory)\n",
        "  # Set the files list to an empty list\n",
        "  files = []\n",
        "\n",
        "#Downloading the regularization images\n",
        "try:\n",
        "    zip_file = hf_hub_download(\n",
        "        repo_id=\"geocine/regularization-images\", \n",
        "        filename=f\"{SDD_CLASS}_v1-5_mse_vae_ddim50_cfg7_n4411.zip\", \n",
        "        revision=\"main\",\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    # Print an error message and set the zip_file variable to None if the download fails or the user doesn't have access\n",
        "    print(f\"An error occurred while downloading the dataset: {e}\")\n",
        "    zip_file = None\n",
        "\n",
        "# Check if the unzip directory has files\n",
        "if len(files) > 0:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Unzip directory has files. Skipping unzip.\")\n",
        "elif zip_file is None:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Skipping unzip because the zip file was not downloaded\")\n",
        "else:\n",
        "  # Run the unzip command\n",
        "  subprocess.run([\"unzip\", \"-j\", zip_file, \"-d\", unzip_directory])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    raise ValueError(\"Please run the Install cell first\")\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "\n",
        "# Incorporate this so that users won't have to crop their images https://github.com/d8ahazard/sd_smartprocess\n",
        "for c in concepts_list:\n",
        "   prompt = c['instance_prompt']\n",
        "   prompt = prompt.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "   print(f\"Uploading instance images for `{prompt}`\")\n",
        "   uploaded = files.upload()\n",
        "   for filename in uploaded.keys():\n",
        "       dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "       # Create the instance_data_dir directory if it does not exist\n",
        "       os.makedirs(c['instance_data_dir'], exist_ok=True)\n",
        "       shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "for c in concepts_list:\n",
        "    data_dir = c['instance_data_dir']\n",
        "    # replace the SDD_TOKEN placeholders with the actual values\n",
        "    data_dir = data_dir.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(data_dir):\n",
        "        # Check if the directory is empty\n",
        "        if len(os.listdir(data_dir)) == 0:\n",
        "            raise ValueError(f\"The directory `{data_dir}` is empty. Please upload some images using the cell above.\")\n",
        "    else:\n",
        "        # Raise an exception if the directory does not exist\n",
        "        raise ValueError(f\"The directory `{data_dir}` does not exist. Please run the Upload cell first.\")\n",
        "\n",
        "NUM_CLASS_IMAGES = 3000 #@param {type:\"number\"}\n",
        "#@markdown `{TOKEN_CLASS}` will be replaced with the token and class name.\n",
        "SAVE_SAMPLE_PROMPT = \"photo of {TOKEN_CLASS}\" #@param {type:\"string\"}\n",
        "SAVE_SAMPLE_PROMPT = SAVE_SAMPLE_PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "MAX_TRAIN_STEPS = 3000 #@param {type:\"number\"}\n",
        "SAVE_INTERVAL = 400 #@param {type:\"number\"}\n",
        "SAVE_MIN_STEPS = 2000 #@param {type:\"number\"}\n",
        "CLEAR_MODELS = True #@param {type:\"boolean\"}\n",
        "SAMPLE_BATCH_SIZE = 4\n",
        "#@markdown If you have experience with training models, you can change more parameters on the code in this cell.\n",
        "\n",
        "PREV_MODEL_STEPS = None\n",
        "g_cuda = None\n",
        "\n",
        "if CLEAR_MODELS:\n",
        "    # Run the rm command using subprocess\n",
        "    subprocess.run([\"rm\", \"-rf\", f\"/content/stable_diffusion_models/{SDD_TOKEN}/*\"])\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "  --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
        "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "  --save_interval=$SAVE_INTERVAL \\\n",
        "  --save_min_steps=$SAVE_MIN_STEPS \\\n",
        "  --save_sample_prompt=\"$SAVE_SAMPLE_PROMPT\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "# --shuffle_after_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "xmvbPv0UJIag"
      },
      "outputs": [],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved models.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "if \"OUTPUT_DIR\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "models_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(models_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "\n",
        "# Get the list of folders in the models folder and check if the samples folder exists and have images, the number of images should be equal to the SAMPLE_BATCH_SIZE\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(models_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    if not os.path.exists(image_folder):\n",
        "        raise ValueError(f\"The folder `{image_folder}` does not exist. Please make sure you have run the Training cell above.\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    if len(images) != SAMPLE_BATCH_SIZE:\n",
        "        raise ValueError(f\"The folder `{image_folder}` does not have {SAMPLE_BATCH_SIZE} images. Please make sure you have run the Training cell above.\")\n",
        "\n",
        "# Check if the number of folders > 0\n",
        "if len(folders) == 0:\n",
        "    raise ValueError(\"No folders found in the models folder. Please make sure you have run the training cell above.\")\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(models_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(models_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@markdown Make sure you have run the Training cell above before running this cell.\n",
        "import os\n",
        "import random \n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, EulerAncestralDiscreteScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "MODEL_STEPS = 2000 #@param {type:\"number\"}\n",
        "\n",
        "# check f'/content/stable_diffusion_models/{{TOKEN}}/{MODEL_STEPS}' exists\n",
        "if not os.path.exists(f'/content/stable_diffusion_models/{{TOKEN}}/{MODEL_STEPS}'):\n",
        "    raise ValueError(f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training cell above.\")\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "if \"PREV_MODEL_STEPS\" not in globals():\n",
        "    raise ValueError(\"Please run the training cell above.\")\n",
        "\n",
        "if MODEL_STEPS != PREV_MODEL_STEPS or g_cuda is None:\n",
        "  PREV_MODEL_STEPS = MODEL_STEPS\n",
        "  model_path = f'/content/stable_diffusion_models/{{TOKEN}}/{MODEL_STEPS}'             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "  model_path = model_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "  scheduler = EulerAncestralDiscreteScheduler(num_train_timesteps=1000, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "  pipe.enable_xformers_memory_efficient_attention()\n",
        "  g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(model_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "SEED = -1  #@param {type:\"number\"}\n",
        "if (SEED < 0):\n",
        "  SEED = random.randint(0, 2**32 - 1) \n",
        "g_cuda.manual_seed(SEED)\n",
        "\n",
        "#@markdown Enter a prompt to generate images from. `{TOKEN_CLASS}` will be replaced with the token and class name.\n",
        "PROMPT = \"photo of {TOKEN_CLASS}\" #@param {type:\"string\"}\n",
        "PROMPT = PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "NEGATIVE_PROMPT = \"\" #@param {type:\"string\"}\n",
        "NUM_SAMPLES = 2 #@param {type:\"number\"}\n",
        "CFG = 8 #@param {type:\"number\"}\n",
        "STEPS = 80 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt=PROMPT,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_images_per_prompt=NUM_SAMPLES,\n",
        "        num_inference_steps=STEPS,\n",
        "        guidance_scale=CFG,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EydphztWBiI"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHvppaFtcFA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "#@markdown This will save chosen checkpoint on Google Drive. You can then download it from there.\n",
        "MODEL_STEPS = 2800 #@param {type:\"number\"}\n",
        "mdl_path = f\"/content/stable_diffusion_models/{{TOKEN}}/{MODEL_STEPS}\"\n",
        "mdl_path = mdl_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "ckpt_path =  mdl_path + \"/model.ckpt\"\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(mdl_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $mdl_path  --checkpoint_path $ckpt_path --half\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "# Check if Google Drive is already mounted\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "NAME = \"aivan\" #@param {type:\"string\"}\n",
        "#@markdown Enter the path to save the model in Google Drive. If left empty, the model will be saved in the root of Google Drive.\n",
        "GDRIVE_PATH = \"Files\" #@param {type:\"string\"}\n",
        "\n",
        "# remove / from start and end of GDRIVE_PATH if they exist\n",
        "GDRIVE_PATH = GDRIVE_PATH.strip('/')\n",
        "MODEL_NAME = f\"{SDD_CLASS}-{MODEL_STEPS}-{SDD_TOKEN}-{NAME}\"\n",
        "if GDRIVE_PATH:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{GDRIVE_PATH}/{MODEL_NAME}.ckpt\"\n",
        "else:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{MODEL_NAME}.ckpt\"\n",
        "\n",
        "# Execute the command\n",
        "!{cmd}\n",
        "print(f\"Model saved at /{GDRIVE_PATH}/{MODEL_NAME}. Wait for 5 minutes before closing\")\n",
        "print(f\"To use your model on other applications make sure to mention \\\"{SDD_TOKEN} {SDD_CLASS}\\\" in the prompt.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "607db476e417971f05b607c2dd14e77ee8262c2c4c20dea422522c60605a222a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
